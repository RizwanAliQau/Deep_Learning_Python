{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet_BasicPattern.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAh5c5CEZdJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug9rYa0sZ7HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile = keras.applications.mobilenet.MobileNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzsSeOcBn-pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip '/content/drive/My Drive/basicpattern_3800.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_iTMvuCaHl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9-6VhBaKBA",
        "colab_type": "code",
        "outputId": "c5ab967b-e19a-4db0-9a0d-85b6ef0b6e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynvimtcHaKLH",
        "colab_type": "code",
        "outputId": "45364c9a-111a-4eaf-d690-36f0f450a16b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)\n",
        "  break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjts7XEbnflG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qloAvgZaKc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJQkEG3VbGY1",
        "colab_type": "code",
        "outputId": "094ee28a-fcbe-400f-ac01-1d127773a988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/content/basicpattern_3800',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3800 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMDUDH_TgkyK",
        "colab_type": "code",
        "outputId": "673d204e-067b-4ee2-b253-35d4ecd81b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 29s 244ms/step - loss: 0.7621 - accuracy: 0.7850\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 24s 206ms/step - loss: 0.4632 - accuracy: 0.8774\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 24s 206ms/step - loss: 0.3192 - accuracy: 0.9119\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 25s 209ms/step - loss: 0.3203 - accuracy: 0.9169\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 24s 206ms/step - loss: 0.2845 - accuracy: 0.9233\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 24s 205ms/step - loss: 0.2328 - accuracy: 0.9390\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 24s 206ms/step - loss: 0.2227 - accuracy: 0.9443\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 24s 203ms/step - loss: 0.2169 - accuracy: 0.9406\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 24s 205ms/step - loss: 0.1991 - accuracy: 0.9493\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 24s 207ms/step - loss: 0.1597 - accuracy: 0.9587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f36c3a9b9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JeGwpRmwGiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0266e33-27cd-4e6f-8877-622621eb4c48"
      },
      "source": [
        "labels_dict = train_generator.class_indices\n",
        "keys_label = list(labels_dict.keys())\n",
        "keys_label[0]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'animal'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPT2b-oarZYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1 = prepare_image('/content/basicpattern_3800/diamond/imgg_104.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzxX1VXiufm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions_position = np.argmax(model.predict(img1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIhVTRxzi1_M",
        "colab_type": "code",
        "outputId": "bd431ebd-df87-41dc-892f-edc24004aff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The give example is belong to class {keys_label[predictions_position]}')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The give example is belong to class diamond\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JraOySBojDq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPkOLQCujLkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='/content/basicpattern_3800/diamond/imgg_104.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}